id,title,selftext,score,num_comments,author,created_utc,url,upvote_ratio,over_18,edited,spoiler,stickied
1jnc3zk,When to use a surrogate key instead of a primary key?,"Hi all!

I am reviewing for interviews and the following question come to mind.

If **surrogate keys** are supposed to be unique identifiers that don't have real world meaning AND if **primary keys** are supposed to reliably identify and distinguish between each individual record (which also don't have real world meaning), then why will someone use a surrogate key? Wouldn't using primary keys be the same? Is there any case in which surrogate keys are the way to go?

P.S: Both surrogate and primary keys are auto generated by DB. Right?

P.S.1: I understand that a surrogate key doesn't necessarily have to be the a primary key, so considering that both have no real meaning outside the DB, then I wonder what the purpose of surrogate keys are.

P.S.2: At work (in different projects), we mainly use natural keys for analytical workloads and primary keys for uniquely identifying a given row. So I am wondering on which kind of cases/projects these surrogate keys will fit. 

",54,47,DataGhost404,2025-03-30 13:12:50,https://www.reddit.com/r/dataengineering/comments/1jnc3zk/when_to_use_a_surrogate_key_instead_of_a_primary/,0,False,False,False,False
1jn7lfp,Do I need to know software engineering to be a data engineer?,As title says ,46,71,Gloomy-Profession-19,2025-03-30 07:53:33,https://www.reddit.com/r/dataengineering/comments/1jn7lfp/do_i_need_to_know_software_engineering_to_be_a/,0,False,False,False,False
1jnh7pu,A dbt column lineage visualization tool (with dynamic web visualization),"Hey dbt folks,

I'm a data engineer and use dbt on a day-to-day basis, my team and I were struggling to find a good open-source tool for user-friendly column-level lineage visualization that we could use daily, similar to what commercial solutions like dbt Cloud offer. So, I decided to start building one...

https://reddit.com/link/1jnh7pu/video/wcl9lru6zure1/player

You can find the repo [here](https://github.com/Fszta/dbt-column-lineage), and the package on [pypi](https://pypi.org/project/dbt-col-lineage/0.1.1/)

**Under the hood**

Basically, it works by combining dbt's manifest and catalog with some compiled SQL parsing magic (big shoutout to sqlglot!).

I've built it as a CLI, keeping the syntax similar to dbt-core, with upstream and downstream selectors.

    dbt-col-lineage --select stg_transactions.amount+ --format html

Right now, it supports:

* Interactive HTML visualizations
* DOT graph images
* Simple text output in the console

**What's next ?**

* Focus on compatibility with more SQL dialects
* Improve the parser to handle complex syntax specific to certain dialects
* Making the UI less... basic. It's kinda rough right now, plus some information could be added such as materialization type, col typing etc

Feel free to drop any feedback or open an issue on the [repo](https://github.com/Fszta/dbt-column-lineage/tree/main)! It's still super early, and any help for testing on other dialects would be awesome. It's only been tested on projects using Snowflake, DuckDB, and SQLite adapters so far.",35,3,Eastern-Ad-6431,2025-03-30 17:11:12,https://www.reddit.com/r/dataengineering/comments/1jnh7pu/a_dbt_column_lineage_visualization_tool_with/,0,False,2025-03-30 17:15:59,False,False
1jnktzw,Passed DP-203 -- some thoughts on its retiring,"i took the Azure DP-203 last week — of course, it’s retiring literally tomorrow. But I figured it is indeed a very broad certification and so it can give a ""grounding"" scope in Azure D.E.

Also, I think it's still super early to go full Fabric (DP-600 or even DP-700), because the job demand is still not really there. Most jobs still demand strong grounding in Azure services even in the wake of Fabric adoption (POCing…).

So of course here, it’s retiring literally tomorrow unfortunately. I have passed the exam with a high score (900+). Also, I have worked (during internship) directly with MS Fabric only. So I would say some skills actually transfer quite nicely (ex: ADF ~ FDF).

---

### Some notes on resources for future exams:

I have relied primarily on [@tybulonazure](https://www.youtube.com/@tybulonazure)’s excellent YouTube channel (DP-203 playlist). It’s really great (watch on 1.8x – 2x speed).  
Now going back to Fabric, I have seen he has pivoted to Fabric-centric content — also a great news!

I also used the official “Guide” book (2024 version), which I found to be a surprisingly good way of structuring your learning. I hope equivalents for Fabric will be similar (TBS…).

---

The labs on Microsoft Learn are honestly **poorly designed** for what they offer.  
**Tip:** @tybul has video labs too — *use these*.  
And for the exams, always focus on **conceptual understanding**, not rote memorization.

Another **important (and mostly ignored)** tip:  
Focus on the **“best practices”** sections of Azure services in Microsoft Learn — I’ve read a lot of MS documentation, and those parts are often more helpful on the exam than the main pages.

---

**Examtopics** is obviously very helpful — but **read the comments**, they’re essential!

---

Finally, I do think it’s a shame it’s retiring — because the “traditional” Azure environment knowledge seems to be a sort of industry standard for companies. Also, the Fabric pricing model seems quite aggressive.

So for juniors, it would have been really good to still be able to have this background knowledge as a base layer.",16,2,EducatedEarthian-99,2025-03-30 19:48:14,https://www.reddit.com/r/dataengineering/comments/1jnktzw/passed_dp203_some_thoughts_on_its_retiring/,0,False,False,False,False
1jn1ko5,Should I stay in part-time role that uses Dagster or do internships in roles that use Airflow,"I am a part time data engineer/integrator who is in school at the moment. I work using Dagster, AWS, Snowflake, and Docker.

I was hoping Dagster would have roles where I lived but it seems everyone prefers Airflow.

Is it worth exploring data engineering internships that use Airflow at the expense of losing my current role? Do you guys see any growth in Dagster?",11,18,Apart-Plankton9951,2025-03-30 01:25:17,https://www.reddit.com/r/dataengineering/comments/1jn1ko5/should_i_stay_in_parttime_role_that_uses_dagster/,0,False,False,False,False
1jnisk7,What is expected of me as a Junior Data Engineer in 2025?,"Hello all, 

I've been interviewing for a proper Junior Data Engineer position and have been doing well in the rounds so far. I've done my recruiter call, HR call and coding assessment. Waiting on the 4th.

I want to be great. I am willing to learn from those of you who are more experienced than me.  
  
Can anyone share examples from their own careers on attitude, communication, soft skills, time management, charisma, willingness to learn and other soft skills that I should keep in mind. Or maybe what I should not do instead.

How should I approach the technical side? There are 1000's of technologies to learn. So I have been learning basics with soft skills and hoping everything works out.

3 years ago I had a labour job and did well in that too. So this grind has caused me to rewire my brain to work in tech and corporate work. I am aiming for 20 years more in this field.

Any insights are appreciated.

Thanks!",9,11,turnwol7,2025-03-30 18:19:54,https://www.reddit.com/r/dataengineering/comments/1jnisk7/what_is_expected_of_me_as_a_junior_data_engineer/,0,False,False,False,False
1jni0xm,Transitioning from DE to ML Engineer in 2025?,"I am a DE with 2 years of experience, but my background is mainly in statistics. I have been offered a position as an ML Engineer (de facto Data Scientist, but also working on deployment - it is a smaller IT department, so my scope of duties will be simply quite wide). 

The position is interesting, and there are multiple pros and cons to it (that I do not want to discuss in this post). However my question is a bit more general - in 2025, with all the LLMs performing quite well with code generation and fixing, which path would you say is more stable long-term - sticking to DE and becoming better and better at it, or moving more towards ML and doing data science projects?

Furthermore, I also wonder about growth in each field - in ML/DS, my fear is that I am not PhD nor excellent mathematician. In DE, on the other hand, my fear is lack of my solid CS/SWE foundations (as my background is more in statistics). 

Ultimately, it is just an honest question, as I am very curious of your perspective on the matter - does moving towards data science projects (XGBoost and other algorithms) in 2025 from DE (PySpark and Airflow) makes sense in 2025? Which path would you say is more reasonable, and what kind of growth I can expect for each position? Personally I am a bit reluctant to switch simply since I have already dedicated 2 years to growing as an DE, but on the other hand I also see how much more and more of my tasks can be automated. Thanks for tips and honest suggestions!",6,11,absurdherowaw,2025-03-30 17:47:04,https://www.reddit.com/r/dataengineering/comments/1jni0xm/transitioning_from_de_to_ml_engineer_in_2025/,0,False,False,False,False
1jnh5oy,"Struggling with Career Path – Stuck in Java, Want to Return to Data Engineering (6.5 YOE)","I've been working in IT for the past 6.5 years. I started as a Java Developer for a year before transitioning into Data Engineering, where I worked with Airflow, GCP, Python, and SQL (BigQuery).

In June 2022, I joined my second company as a Data Engineer, but after just six months, the project was shelved, and I was moved to a Java-based project (Spring Boot, Kafka, etc.). This happened during a market downturn and layoffs, so I was grateful to still have a job.

Now, after two years in this role, I feel stuck. I struggle with coding, don’t enjoy Java, and constantly feel like an imposter. I know for sure that I don’t want to continue in Java and Spring Boot. However, I’ve stayed in this role because it’s high-paying, and I have family responsibilities (supporting a family of five).

I want to transition back into Data Engineering, but now the job market expects a higher level of expertise given my experience and salary range. I’m unsure about the best way to upskill and make this switch without a major setback.

How can I strategically transition back into Data Engineering while balancing financial stability? Would love advice from those who have made similar career shifts.

Thanks in advance!",5,9,ishaheenkhan,2025-03-30 17:08:46,https://www.reddit.com/r/dataengineering/comments/1jnh5oy/struggling_with_career_path_stuck_in_java_want_to/,0,False,False,False,False
1jn4ptx,Introducing AnuDB: A Lightweight Embedded Document Database,"**AnuDB** \- a lightweight, embedded document database.

# Key Features

* **Embedded & Serverless**: Runs directly within your application - no separate server process required
* **JSON Document Storage**: Store and query complex JSON documents with ease
* **High Performance**: Built on RocksDB's LSM-tree architecture for optimized write performance
* **C++11 Compatible**: Works with most embedded device environments that adopt C++11
* **Cross-Platform**: Supports both Windows and Linux (including embedded Linux platforms)
* **Flexible Querying**: Rich query capabilities including equality, comparison, logical operators and sorting
* **Indexing**: Create indexes on frequently accessed fields to speed up queries
* **Compression**: Optional ZSTD compression support to reduce storage footprint
* **Transactional Properties**: Inherits atomic operations and configurable durability from RocksDB
* **Import/Export**: Easy JSON import and export for data migration or integration with other systems

Checkout README for more info: [https://github.com/hash-anu/AnuDB](https://github.com/hash-anu/AnuDB)",3,0,Fine-Package-5488,2025-03-30 04:26:19,https://www.reddit.com/r/dataengineering/comments/1jn4ptx/introducing_anudb_a_lightweight_embedded_document/,0,False,False,False,False
1jnj03e,Serialisation and de-serialisation?,"I just got to know that even in today's OLAP era, but while communicating b/w the systems internally they convert it to row based storage even if the warehouses are columnar type...
This made me sickkk I never knew this at all!

So does this mean serialisation and de-serialisation?? 
I see these terms vary across many architecture ex: In spark they mention these terminologies when the data needs to searched at different instances.. they say data needs to be de-serialised which takes time...

But I am not clear how do I need to think when I hear these terminologies!!!

Source:
https://www.linkedin.com/posts/dipankar-mazumdar_dataengineering-softwareengineering-activity-7307566420828065793-LuVZ?utm_source=share&utm_medium=member_android&rcm=ACoAADeacu0BUNpPkSGeT5J-UjR35-nvjHNjhTM",4,2,Excellent-Level-9626,2025-03-30 18:29:00,https://www.reddit.com/r/dataengineering/comments/1jnj03e/serialisation_and_deserialisation/,0,False,False,False,False
1jnhk94,how to deal with azure vm nightmare?,"i am building data pipelines. i use azure vms for experimentation on sample data. when im not using them, i need to shut them off (working at bootstrapped startup).

when restarting my vm, it randomly fails. it says an allocation failure occurred due to capacity in the region (usually us-east). the only solution ive found is moving the resource to a new region, which takes 30–60 mins.

how do i prevent this issue in a cost-effective manner? can azure just allocate my vm to whatever region is available?

i’ve tried to troubleshoot this issue for weeks with azure support, but to no avail.

thanks all! :)
",3,12,BigCountry1227,2025-03-30 17:26:28,https://www.reddit.com/r/dataengineering/comments/1jnhk94/how_to_deal_with_azure_vm_nightmare/,0,False,False,False,False
1jn7g1f,3 years into Devops Engineering trying to move to Data Engineering,"I came to know that most of the skillset are matching 
in this 2 fields, apart from learning SQL, pyspark.

so would this be a better switching career ?",1,11,Blacktweeter,2025-03-30 07:42:11,https://www.reddit.com/r/dataengineering/comments/1jn7g1f/3_years_into_devops_engineering_trying_to_move_to/,0,False,False,False,False
1jnrfgm,dezoomcamp project,"Real-world data engineering practice! 🏗️ Built an end-to-end **data pipeline** using GCP, BigQuery, dbt, and Airflow to analyze Airbnb trends. Learning + hands-on = the best combo! 💡  
\#dezoomcamp #dataengineering #learningbydoing",0,2,Impressive_Trip1382,2025-03-31 00:57:43,https://www.reddit.com/r/dataengineering/comments/1jnrfgm/dezoomcamp_project/,0,False,False,False,False
1jnrf68,dezoomcamp project,"How I made my Airbnb analysis efficient:  
🔹 **Staging layer**: Standardized & cleaned raw data  
🔹 **Core layer**: Built fact & dimension tables  
🔹 **Analytics dataset**: Ready for insights!  
\#dezoomcamp #analyticsengineering",0,1,Impressive_Trip1382,2025-03-31 00:57:17,https://www.reddit.com/r/dataengineering/comments/1jnrf68/dezoomcamp_project/,0,False,False,False,False
1jnrev3,dezoomcamp project,"Orchestrating **dbt runs with Airflow** ensures transformations only happen when new data arrives. No wasted compute, no stale dashboards—just efficient workflows! 🔥  
\#dezoomcamp #dbtcore #airflow",0,0,Impressive_Trip1382,2025-03-31 00:56:49,https://www.reddit.com/r/dataengineering/comments/1jnrev3/dezoomcamp_project/,0,False,False,False,False
1jnrehd,dezoomcamp project,"End-to-end pipeline **deployment steps**:  
1️⃣ Terraform: Set up GCS & BigQuery  
2️⃣ Python: Load data to GCS  
3️⃣ dbt: Transform data  
4️⃣ Airflow: Orchestrate  
5️⃣ Looker: Visualize 📊  
\#dezoomcamp",0,0,Impressive_Trip1382,2025-03-31 00:56:16,https://www.reddit.com/r/dataengineering/comments/1jnrehd/dezoomcamp_project/,0,False,False,False,False
1jnre2y,dezoomcamp project,"Implemented **SCD Type 2** in dbt for tracking historical host changes. Now I can analyze how hosts evolve over time and their impact on reviews and pricing! 🔄  
\#dezoomcamp #dbt #datawarehousing",0,0,Impressive_Trip1382,2025-03-31 00:55:39,https://www.reddit.com/r/dataengineering/comments/1jnre2y/dezoomcamp_project/,0,False,False,False,False
1jnqdug,First Major DE Project,"Hello everyone, I am working on this end-to-end process for processing Pitch-by-Pitch data with some inner workings for also enabling analytics to be done directly from the system with little set up. I began this project because I use different computers and it became an issue switching from device to device when it came to working on these projects, and I can use it as my school project to cut down on time spent. I have it posted on my GitHub here and would love for any feedback any of you could have on the overall direction of this project and ways I could improve this Thank you!

Github Link: [https://github.com/jwolfe972/mlb\_prediction\_app](https://github.com/jwolfe972/mlb_prediction_app)",1,1,scuffed12s,2025-03-31 00:02:37,https://www.reddit.com/r/dataengineering/comments/1jnqdug/first_major_de_project/,0,False,False,False,False
1jnlsu5,Example for complex data pipeline,"Hi community,

After working as a data analyst for several years, I've noticed a gap in tools for interactively exploring complex ETL pipeline dependencies. Many solutions handle smaller pipelines well, but struggle with 200+ tasks.

For larger pipelines, we need robust traversal features, like collapsing/expanding nodes to focus on specific sections during development or debugging. I've used `networkx` and `mermaid` for subgraph visualization, but an interactive UI would be more efficient.

I've developed a prototype and am seeking example cases to test it. I'm looking for pipelines with 60+ tasks and complex dependencies. I'm particularly interested in the challenges you face with these large pipelines. At my workplace, we have a 1500+ task pipeline, and I'm curious if this is a typical scale.

Specifically, I'd like to know:

* What challenges do you face when visualizing and managing large pipelines?
* Are pipelines with 1500+ tasks common?
* What features would you find most useful in a tool for this purpose?

If you can share sanitized examples or describe the complexity of your pipelines, it would be very helpful.

Thanks.",2,2,EliyahuRed,2025-03-30 20:29:36,https://www.reddit.com/r/dataengineering/comments/1jnlsu5/example_for_complex_data_pipeline/,0,False,False,False,False
1jnlm9u,"As a data analytics/data science professional, how much data engineering am I supposed to know? Any advice is greatly appreciated","I am so confused. I am looking for roles in BI/analytics/data science and it seems data engineering has just taken over the entire thing or most of it, atleast. BI and DBA is just gone and everyone now wants cloud dev ops and data engineering stack as part of a BI/analytics role? Am I now supposed to become a software engineer and learn all this stack (airflow, airtable, dbt, hadoop, pyspark, cloud, devops etc?) - this seems so overwhelming to me! How am I supposed to know all this in addition to data science, strategy, stakeholder management, program management, team leadership....so damn exhausting! Any advice on how to navigate the job market and land BI/data analytics/data science roles and how much realistic data engineering am I supposed to learn?",0,6,CreditArtistic1932,2025-03-30 20:21:44,https://www.reddit.com/r/dataengineering/comments/1jnlm9u/as_a_data_analyticsdata_science_professional_how/,0,False,False,False,False
1jndfr9,Building a Cloud-Based Data Pipeline for Personal Use/Learning/Projects,"I am a data/functional analyst looking to get a better grasp on 'end-to-end data management and processing' (in quotations as that's the term my direct lead used when we aligned regarding my career objectives for the year, which definitely matches with my current interests).

Given this objective, my own interest in gaining a better grasp on general principles and functions of Data Engineering (and later on, Data Science), as well as a personal project I'm looking to finish for myself/my own portfolio by the end of the year, I'm looking for a cloud-based data pipeline solution for me to spend my role's training stipend on -- though I'm willing (and allowed) to use some of my personal funds on this as well since it's both for career progression and personal fun.

I started looking for small-scale subscriptions for some of the platforms we've previously used at work (AWS, Databricks), but the consensus I've gotten is that cost-wise, I'm potentially better off with multiple smaller platforms that I can just weave together, instead of going for platforms normally designed for enterprise use. And so I come here for help!

*(Though if this is not the right community for me to ask this, please let me know where instead)*

# Budget and Scope

* Base budget is a $200 stipend from our department, which refreshes at the end of the year
* I'm willing to add another $200-300/year, if necessary
* I'm from South-East Asia (converting our local currency, in case regional pricing matters)
* I prefer platforms/solutions that come with upfront costs instead of per-pull/use costs, so that's it's easier to manage the finances involved
* Languages I'm comfortable with are Python and SQL, since these are what I mainly use for work, but willing to learn basics of new languages where necessary 
* Since I will be using my personal computer, which is not that powerful currently, I am looking for a pipeline/platform that I can use completely via cloud (including running training models) 

# Learning Objectives 

*(aka things I want my platform/s to be able to do)*

**1. Data Gathering/Ingestion/Validation/Transformation/Storage**

* Obviously not too familiar with this step currently, so I ended up lumping a bunch of them together, but essentially ETL
* In terms of data I intend to use, I have three main sources I intend to work my way through, from simple to complex: **(1)** will be starting with ingesting CSV files I get from third-party free data providers like Kaggle, **(2)** then moving on to structured databases from sports stat sites such as BBREF, before  eventually work my way to **(3)** automating data collection from publicly available video games I normally play (Dota 2, Path of Exile -- if it matters)
* I want to be able to load these into SQL tables that I can regularly query form

**2. Data Querying and Extract Cloud Storage**

* I want to then be able to set it up so that I can easily query and then store-via-cloud what I need.
* To make my intention clear, most of my work experience is with AWS Athena and S3, so I hope to get platforms that function similarly.

**3. Cloud-Based Data Processing, Machine Learning, and Visualization**

* I currently do majority of my post-query data processing and modelling locally on my work laptop on Jupyter (via the Anaconda distribution), but one of my key objectives is learning to do all of these on cloud (especially since my peronal computer I'll be using would obviously not be as powerful as what I use for work)
* I definitely prefer Notebook-like environments, so perhaps something like AWS EMR
* My main experience at this level is mainly with Python (using specific packages such as Pandas, Numpy, Matplotlib, Numpy, Sklearn, etc.), but I'm looking to do more PySpark as well

**4. EXTRA/OPTIONAL: Dashboard Creation and Hosting**

* If I can get a platform/pipeline that will allow me to host interactive dashboards for me to just embed in my portfolio, that would be a plus, but I am very easily willing to drop this should it not fit my budget

#  Final Remarks

* Want to learn ETL, and cloud-based data processing on a personal data pipeline and processing platform/solution that also has SQL capabilities -- in line with my career and personal learning objectives for the year 
* Tried looking into personal subscriptions for 360 solutions like Databricks and AWS Sagemaker Unified Studio, but was told that for what I want I might be better off with patching together T2 solutions or something along those lines -- but I imagine this would be much more tricky to set up ",1,1,bacon9001,2025-03-30 14:20:16,https://www.reddit.com/r/dataengineering/comments/1jndfr9/building_a_cloudbased_data_pipeline_for_personal/,0,False,False,False,False
1jnrdm2,dezoomcamp project,"Ever wondered why some Airbnb listings are way more expensive? My project explores price trends, demand drivers, and traveler-friendly insights based on NYC Airbnb data! 🏠📈

\#dezoomcamp #dataanalysis #airbnb",0,2,Impressive_Trip1382,2025-03-31 00:54:57,https://www.reddit.com/r/dataengineering/comments/1jnrdm2/dezoomcamp_project/,0,False,False,False,False
1jnrd0h,DEZOOMCAMP Project,"Lessons learned from loading Airbnb data into GCP:  
✔️ Use **autodetect schema** in BigQuery for flexibility  
✔️ Handle CSV quirks with proper configs  
✔️ Optimize storage with partitioning  
\#dezoomcamp #gcp #dataengineering",0,0,Impressive_Trip1382,2025-03-31 00:54:01,https://www.reddit.com/r/dataengineering/comments/1jnrd0h/dezoomcamp_project/,0,False,False,False,False
1jnrb6y,Data Camp Data engineering certification help,Hi I’ve been working through the data engineer in SQL track on DataCamp and decided to try the associate certification exam. There was quite a bit that didn’t seem to have been covered in the courses. Can anyone recommend any other resources to help me plug the gap please? Thanks,0,1,Bodhisattva-Wannabe,2025-03-31 00:51:17,https://www.reddit.com/r/dataengineering/comments/1jnrb6y/data_camp_data_engineering_certification_help/,0,False,False,False,False
1jnq405,Unstructured to Structured,"Hi folks,
I know there have been some discussions on this topic; but given we had lot of development in technology and business space; would like to get your input on
1. How much is this still a problem?
2. Do agentic workflows open up some new challenges?
3. Is there any need to convert large excel files into  SQL tables?

",0,1,Fantastic-Cup-990,2025-03-30 23:48:51,https://www.reddit.com/r/dataengineering/comments/1jnq405/unstructured_to_structured/,0,False,False,False,False
1jnj9bw,Collect old news articles from mainstream media.,"What is the best way to collect like >10 years old news articles from the mainstream media and newspapers?
 ",0,1,SaintPellegrino4You,2025-03-30 18:39:53,https://www.reddit.com/r/dataengineering/comments/1jnj9bw/collect_old_news_articles_from_mainstream_media/,0,False,False,False,False
1jna701,"I am learning data engineering from a course. I am a fresher with no job experience, a commerce background, and a two-year gap.",Will any company hire me? What certificate could I obtain that would help me?,0,9,_winter_rabbit_,2025-03-30 11:12:06,https://www.reddit.com/r/dataengineering/comments/1jna701/i_am_learning_data_engineering_from_a_course_i_am/,0,False,False,False,False
1jnmrm5,Data Stack,"What do you think about the progress into [agentic data stack](https://goagentdata.com/)?  
",0,1,jb_nb,2025-03-30 21:11:28,https://www.reddit.com/r/dataengineering/comments/1jnmrm5/data_stack/,0,False,False,False,False
1jnjmkl,Why is table extraction still not solved by modern multimodal models?,"There is a lot of hype around multimodal models, such as Qwen 2.5 VL or Omni, GOT, SmolDocling, etc. I would like to know if others made a similar experience in practice: While they can do impressive things, they still struggle with table extraction, in cases which are straight-forward for humans.

Attached is a simple example, all I need is a reconstruction of the table as a flat CSV, preserving empty all empty cells correctly. Which open source model is able to do that?

https://preview.redd.it/xg8f0624jvre1.png?width=1650&format=png&auto=webp&s=4c0a22d833cb308534abf4dc38b1b12581a6e227

",0,0,Electronic-Letter592,2025-03-30 18:55:50,https://www.reddit.com/r/dataengineering/comments/1jnjmkl/why_is_table_extraction_still_not_solved_by/,0,False,False,False,False
1jn7kvr,Junior vs Senior role,"What is the difference between a junior and senior in this role? How much can you really know in data engineering; get the data, clean it, dump it somewhere with a cloud service. 

But what would take someone from a junior role to a senior role? Is it just the number years of experience? 

",0,18,Gloomy-Profession-19,2025-03-30 07:52:21,https://www.reddit.com/r/dataengineering/comments/1jn7kvr/junior_vs_senior_role/,0,False,False,False,False
