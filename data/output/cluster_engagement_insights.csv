cluster,keywords,avg_score,avg_comments,avg_word_count,avg_sentiment,avg_char_count,avg_readability,avg_sentence_count,avg_syllable_count,avg_smog_index,pct_has_url,pct_has_code,top_30%_post_count,middle_40%_post_count,bottom_30%_post_count,example_post,score_rank,comment_rank
3,"files, table, tables, query, source, file, example, per, type, daily, load, csv, rows, delta, user, add, stored, sources, error, excel, raw, single, dataset, records, row, date, column, update, script, keys, columns, manually, clean, metrics, list, result, format, results, times, pull, extract, structure, postgresql, select, values, fact, million, external, request, name, call, view, reports, truth, customer, automatically, output, surrogate, minutes, updates, report, partitioning, topic, sometimes, downstream, partition, primary, import, slow, send, dimensions, nested, processed, sales, correct, updated, dimension, hour, sync, export, message, procedures, views, instance, filter, bronze, min, validate, generate, mapping, mysql, address, join, scd, reads, notebook, evaluation, ads, goes, repeating, condition, fails, normalized, adding, record, names, blob, parameters, steps, insert, count, minute, member, convert, whenever, click, location, dataframes, concept, entry, folder, unique, ensure, timestamp, hive, hash, addresses, window, entirely, conversion, constraints, params, pulling, snapshots, keeps, destination, partitioned, loaded, bucket, happen, active, split, transactions, generated, flat, status, receive, merge, gcs, predictions, plain, containing, sink, anybody, index, metastore, delete, ids, temp, adls, vehicle, giving, csvs, incremental, aggregation, text, snapshot, aggregated, sourced, creates, partitions, exist, initially, rdbms, cache, statements, relationship, ingested, saw, facebook, updating, inefficient, copy, contains, entries, straightforward, combine, parse, pdfs, aggregate, incoming, duplicates, page, rdd, named, sends, duplicate, outputs, historic, fetch, string, sftp, wouldnt, returns, prepared, feed, attributes, oltp, filters, reference, inserts, capture, telemetry, html, clustering, max, particular, dbs, submit, frequency, arrival, optional, userid, kpis, secondary, vehicles, anomalies, mins, pdf, randomly, marts, effect, repeat, separately, modify, sign, conditions, generic, sliding, denormalized, transformed, payload, backfill, chunks, url, joining, usersessions, endpoint, null, archive, linked, instances, serve, dim, dictionary, vpc, detect, failing, folders, incrementally, campaigns, encountered, transformlayer, datalake, hashes, utc, constructing, uploaded, sent, tableb, computed, tablea, schemalimitedreader, rewriting, jsonb, revenue, hourly, newly, connections, summaries, standardized, operation, empty, attached, permissions, dump, upserts, uniqueness, frame, wish, automatic, distinct, falls, consuming, returned, oriented, avoiding",12.8,8.4,173.0,-0.701,1063.3,57.1,9.7,259.1,10.4,20.3,21.3,160,337,95,"[https://github.com/turbolytics/sql-flow](https://github.com/turbolytics/sql-flow)

**The goal of SQLFlow is to bring the simplicity of DuckDB to streaming data.**

SQLFlow is a high-performance stream processing engine that simplifies building data pipelines by enabling you to define them using just SQL. Think of SQLFLow as a lightweight, modern Flink.

SQLFlow models stream-processing as SQL queries using the [DuckDB SQL dialect](https://duckdb.org/docs/sql/introduction.html). Express your entire stream processing pipeline—ingestion, transformation, and enrichment—as a single SQL statement and configuration file.

Process [10's of thousands of events per second](https://sql-flow.com/docs/tutorials/clickhouse-sink) on a single machine with low memory overhead, using Python, DuckDB, Arrow and Confluent Python Client.

Tap into the DuckDB ecosystem of tools and libraries to build your stream processing applications. SQLFlow supports [parquet](https://sql-flow.com/docs/tutorials/s3-parquet-sink), csv, json and [iceberg](https://sql-flow.com/docs/tutorials/iceberg-sink). Read data from Kafka.",1,4
2,"engineer, job, experience, really, years, company, role, year, feel, advice, started, hello, field, career, got, science, tech, someone, companies, technical, move, skills, level, long, months, background, next, bit, roles, appreciated, analyst, top, may, course, path, days, ago, ask, month, look, market, hours, position, break, amazon, week, less, forward, ill, interviews, person, least, almost, though, said, pay, growth, masters, situation, coding, scientist, decisions, exam, asking, senior, learned, previous, manager, switch, applying, title, major, finding, stay, hoping, told, growing, university, noticed, havent, taking, des, employees, salary, opportunities, swe, degree, guidance, money, reasons, student, willing, took, junior, decide, feeling, away, finance, grow, previously, lead, honestly, becoming, certification, perfect, reasonable, consulting, yoe, finished, school, program, decent, area, study, hiring, spent, financial, statistics, graduate, short, spend, startup, comment, sub, prior, positions, expertise, internship, lately, review, scope, land, professional, java, joined, architect, lots, certifications, covered, college, leave, knows, direction, ended, received, relatively, talking, exists, reddit, left, fear, age, linkedin, anymore, europe, close, stick, difference, contract, city, expecting, boot, paid, rejected, period, waiting, opportunity, switched, dsa, game, spring, companys, lol, phd, yrs, screening, frustrating, stand, home, laid, meta, freelance, hired, hands, credit, hire, posted, intelligence, six, sorry, finish, continue, upskill, unsure, progress, dba, internships, fits, gonna, graduated, faang, global, prepare, opinions, landed, guy, mention, director, msc, leans, tough, clue, reviews, began, gone, culture, usd, accepted, firm, india, profile, fellow, fulltime, leading, consultant, blah, admin, exp, earlier, five, obviously, layoffs, official, barely, crack, responsibilities, exams, corporate, recruiter, careers, semester, whos, chinese, certificate, candidate, cloudera, family, preferably, imposter, double, mba, obtain, enjoyed, friend, chances, postings, bachelors, raise, kill, grad, recruiters, nobody, poor, macbooks, cto, regions, confused, navigate, confidence, depth, conversation, cheers, tier, surprised, wanna, noob, grown",12.1,9.2,159.9,-0.618,974.2,56.6,9.0,239.0,10.0,17.3,15.4,193,381,119,"Hi all!

I am reviewing for interviews and the following question come to mind.

If **surrogate keys** are supposed to be unique identifiers that don't have real world meaning AND if **primary keys** are supposed to reliably identify and distinguish between each individual record (which also don't have real world meaning), then why will someone use a surrogate key? Wouldn't using primary keys be the same? Is there any case in which surrogate keys are the way to go?

P.S: Both surrogate and primary keys are auto generated by DB. Right?

P.S.1: I understand that a surrogate key doesn't necessarily have to be the a primary key, so considering that both have no real meaning outside the DB, then I wonder what the purpose of surrogate keys are.

P.S.2: At work (in different projects), we mainly use natural keys for analytical workloads and primary keys for uniquely identifying a given row. So I am wondering on which kind of cases/projects these surrogate keys will fit. 

",2,1
5,"would, ive, engineering, work, working, tools, project, currently, looking, much, thanks, team, anyone, better, well, think, good, love, everyone, learning, projects, hey, people, analytics, learn, solution, youre, software, big, hear, start, worked, actually, engineers, stack, real, recently, part, advance, kind, appreciate, especially, post, development, resources, thats, open, share, curious, thank, others, thoughts, management, practice, suggestions, free, hard, teams, guys, research, knowledge, quite, focus, folks, offer, stuff, practices, enough, personal, starting, community, opensource, documentation, interested, isnt, worth, gcp, future, governance, industry, options, world, considering, seen, ideas, security, tips, side, important, examples, came, clear, fast, mainly, fit, past, recommend, whether, several, online, become, yet, training, recommendations, solid, moving, developer, fabric, strong, hope, courses, deep, helpful, planning, setting, completely, valuable, mind, microsoft, focused, exploring, prefer, general, goal, interesting, fully, terms, seem, computer, potential, consider, risk, programming, helped, scraping, devops, languages, basics, handson, shift, happy, dagster, youve, experienced, expensive, challenge, ideally, experiences, definitely, transition, automation, scratch, taken, dev, mentioned, yes, relevant, limited, concepts, technology, problems, couple, overall, strategy, technologies, demand, regarding, sap, designing, legacy, seeing, businesses, rdataengineering, behind, organization, clients, soon, towards, topics, pros, improving, hand, lack, heard, space, matter, honest, oracle, potentially, enjoy, reason, portfolio, switching, welcome, life, involved, opinion, deal, pricing, principles, youtube, faced, sqlmesh, videos, onprem, scala, terraform, info, smart, perspective, computing, allowed, success, longterm, resource, involves, biggest, likely, low, agents, offered, fairly, rough, org, realistic, talk, traditional, guide, content, expert, struggle, harder, paths, llms, theoretical, expectations, totally, helping, usual, beginner, primarily, gain, higher, integrations, daytoday, diving, paying, interest, wed, cover, stable, transitioning, skill, budget, comfortable, studies, infra, recent, bonus, felt, setups, greatly, studio, human, bigger, promotion, hybrid, rag, agent, jvm, decided, insight, weeks, supposed, medium, rely, longer, goals, broken, seriously, house, posts, communication, organizations, choosing, trends, fundamentals, whove, gotten, capacity, breaks, automating, scientists, collection, reach, journey, beginning, sourcing, cheaper, serious, toward, tend, advanced, objectives, majority, predictive, comprehensive, eager, fixing, areas, gap, fun, fresh, chatgpt, stacks, checkout, painful, focusing, figuring, publish, kinds, tooling, operate, discuss, focuses, center, researching, discover, sets, awesome, udemy, self, moment, selfhosting, outdated, dive, education, aiml, professionals, watch, snowpark, private, visual, balance, prod, looker, grasp, startups, worried, performing, subject, functional, checking, cut, founder, lessons, articles, prefect, messy, informatica, amazing, chance, passion, materials, challenging, efforts, members, onpremise, excited, experts, lost, expand, fintech, openmetadata, essential, prep, cool, anyones, crucial, todays, bootcamps, sounds, contracts, mle, digging, heavily, absolute, strategic, meanwhile, piece, cheap, studying, bits, followed, solely, freelancing, trend, material, kaggle, plsql, sections, evaluate, mindset, news, ecommerce, tip, preparing, retail, assessment, workplace, exciting, agile, ultimately, media, baseline, learnings, discussions, predict, promising, prepping, genuinely, midsized, regular, catch, youll, sprint, slack, broader, accessible, suite, surface, confident, tasked, mature",12.0,8.5,149.3,-0.617,914.8,54.5,8.5,223.9,9.8,18.6,16.6,221,439,137,"[https://github.com/turbolytics/sql-flow](https://github.com/turbolytics/sql-flow)

**The goal of SQLFlow is to bring the simplicity of DuckDB to streaming data.**

SQLFlow is a high-performance stream processing engine that simplifies building data pipelines by enabling you to define them using just SQL. Think of SQLFLow as a lightweight, modern Flink.

SQLFlow models stream-processing as SQL queries using the [DuckDB SQL dialect](https://duckdb.org/docs/sql/introduction.html). Express your entire stream processing pipeline—ingestion, transformation, and enrichment—as a single SQL statement and configuration file.

Process [10's of thousands of events per second](https://sql-flow.com/docs/tutorials/clickhouse-sink) on a single machine with low memory overhead, using Python, DuckDB, Arrow and Confluent Python Client.

Tap into the DuckDB ecosystem of tools and libraries to build your stream processing applications. SQLFlow supports [parquet](https://sql-flow.com/docs/tutorials/s3-parquet-sink), csv, json and [iceberg](https://sql-flow.com/docs/tutorials/iceberg-sink). Read data from Kafka.",3,3
1,"data, like, need, want, get, new, time, also, one, know, dont, way, make, something, even, different, trying, help, could, best, used, lot, databricks, things, process, current, many, find, see, still, every, first, around, without, might, right, since, question, business, based, done, seems, sure, two, already, able, found, understand, day, getting, wondering, access, problem, questions, made, similar, another, take, tried, going, please, maybe, specific, idea, google, change, however, full, needs, jobs, possible, say, small, back, theres, point, last, anything, whats, issue, reading, given, end, cant, wanted, come, needed, within, always, far, didnt, give, making, thing, pretty, great, setup, try, product, value, writing, else, let, often, makes, plan, search, sense, thinking, step, high, later, understanding, basically, context, either, mostly, information, input, whole, actual, entire, available, following, various, requirements, little, version, lets, theyre, together, never, option, takes, comes, huge, details, book, adf, super, figure, easily, means, task, link, wrong, size, missing, stuck, put, thought, weve, edit, feels, old, department, gets, simply, moved, probably, show, email, early, country, due, coming, points, related, looks, client, ones, base, final, struggling, bunch, remote, books, total, ground, smaller, certain, arent, drop, second, along, number, return, apply, range, asked, answer, usually, outside, three, expect, amount, marketing, mean, state, live, complicated, rather, required, head, proper, hadoop, quickly, match, care, changed, fine, drive, migrate, finally, comments, hit, ingest, today, non, tell, save, wonder, facing, stats, present, extremely, target, git, wont, follow, loop, public, exactly, supporting, products, website, group, analysts, internal, term, monthly, offers, cannot, nice, rest, airbyte, considered, highly, powerbi, solve, implementing, article, ever, note, delivery, rate, constantly, believe, sort, heavy, quick, completed, develop, developing, necessary, docs, original, meaning, purpose, lines, complete, line, obvious, guess, ingesting, ran, frequently, nothing, customers, half, domain, initial, assume, choice, somehow, whatever, familiar, fivetran, mistakes, says, saying, thousands, ssis, gives, video, english, links, average, dealing, choose, kinda, couldnt, download, hundreds, windows, lab, went, somewhere, matters, wasnt, push, messages, successfully, connection, lower, travel, generally, price, listings, happens, reached, numbers, applied, basis, difficult, implementation, generation, pressure, direct, rules, decision, pick, requirement, wants, answers, near, erp, consistent, cons, normal, beyond, approaches, discussion, passed, series, patterns, poc, stop, unfortunately, figured, terminal, refresh, additional, failed, play, possibly, identify, sample, crazy, metric, limit, ton, party, comparison, shouldnt, wait, despite, aligned, boss, anywhere, transfer, olap, network, ability, internet, hitting, eventually, luck, estimate, upon, worse, worry, levels, gaps, story, depending, changing, forget, perhaps, recovery, bottlenecks, objective, region, regularly, techniques, normally, dollars, kimball, cause, kpi, engagement, lists, increase, pass, assigned, frustrated, premise, description, colleague, expected, improvement, exact, mess, appropriate, consultants, notes, personally, django, computers, recommended, reality, office, gpt, throughout, leads, calculate, labels, assuming, apart, geocoding, effective, iam, okay, unstructured, peak, wide, spreadsheet, master, argument, encounter, orders, turned, became, discount, fancy, jira, hell, sas, usecase, hot, tldr, lose, reverse, trial, class, elt, detail, thread, alongside, social, meet, aware, action, newbie, survey, intend, known, mix, hence, beneficial, knowing, prioritize, interact, missed, adhoc, batches, cold, threads, grant, campaign, stock, realized, rebuild, aka, anyway, prevent, lazy, establish, scrum, tweak, remember, extension, students, rule, responsibility, bases, sell, rolling, buffering, games, tackled, fair, manipulate, introduction, incorporate, gave, chain, liked, fundamental, notice, broke, crm, relies, ensuring, stakeholders, colleagues, downside, specialist, estate, noticing, solves, deliver, buy, plug, internally, kept, detailed, word, proof, older, subset, mart, matching, converted, tsql, critical, adoption, literally, matches",11.9,8.6,147.1,-0.621,901.5,54.7,8.4,220.7,9.7,18.6,16.3,222,450,142,"[https://github.com/turbolytics/sql-flow](https://github.com/turbolytics/sql-flow)

**The goal of SQLFlow is to bring the simplicity of DuckDB to streaming data.**

SQLFlow is a high-performance stream processing engine that simplifies building data pipelines by enabling you to define them using just SQL. Think of SQLFLow as a lightweight, modern Flink.

SQLFlow models stream-processing as SQL queries using the [DuckDB SQL dialect](https://duckdb.org/docs/sql/introduction.html). Express your entire stream processing pipeline—ingestion, transformation, and enrichment—as a single SQL statement and configuration file.

Process [10's of thousands of events per second](https://sql-flow.com/docs/tutorials/clickhouse-sink) on a single machine with low memory overhead, using Python, DuckDB, Arrow and Confluent Python Client.

Tap into the DuckDB ecosystem of tools and libraries to build your stream processing applications. SQLFlow supports [parquet](https://sql-flow.com/docs/tutorials/s3-parquet-sink), csv, json and [iceberg](https://sql-flow.com/docs/tutorials/iceberg-sink). Read data from Kafka.",4,2
0,"python, pipelines, azure, cloud, aws, dbt, etl, build, code, tool, building, snowflake, airflow, built, architecture, approach, running, systems, feedback, performance, support, platform, power, tasks, design, testing, easy, cost, pyspark, realtime, platforms, insights, solutions, issues, complex, quality, basic, streaming, dashboards, local, features, works, costs, integration, services, duckdb, manage, useful, catalog, apache, workflows, reporting, cases, environment, production, blog, easier, uses, main, modeling, common, infrastructure, application, web, docker, improve, bad, speed, existing, faster, compute, core, structured, scale, provide, managed, managing, control, lambda, suggest, heres, workloads, backend, machine, ways, including, containers, automated, modern, orchestration, environments, saas, llm, frameworks, specifically, challenges, framework, pain, linux, automate, providers, serverless, github, realworld, keeping, workflow, cicd, servers, plus, scaling, developers, ecosystem, package, applications, distributed, helps, repo, kubernetes, unit, integrate, practical, locally, visualization, shared, deploy, designed, implemented, frontend, capabilities, container, structures, vendor, commercial, volume, explore, typically, cleaning, observability, native, reliable, sharing, complexity, apps, pattern, enterprise, significant, oop, robust, debugging, includes, warehousing, compared, latency, happening, scalability, libraries, lightweight, flows, tested, migration, powerful, foundation, modular, effort, youd, popular, packages, numpy, analyze, factory, flexibility, microservices, yaml, breaking, operational, chat, scalable, deployment, host, maintaining, nifi, compliance, readme, effectively, zero, serving, flask, typical, secure, increasingly, benefits, cloudbased, natural, box, imagine, spending, configuration, highperformance, unified, browser, architectures, particularly, tuning, gizmosql, unity, leverage, massive, leveraging, significantly, developed, impact, stories, publishing, optimized, evaluating, websites, billing, cloudflare, departments, central, airbnb, minimal, failures, streamlit, reducing, endtoend, behavior, machines, tradeoffs, optimize, limits, alternative, timeseries, accounts, generating, concerns, pure, jupyter, improvements, ease, health, front, compatible, nature, deeper, face, datahub, bottleneck, enable, gen, describe, builder, cli, alternatives, integrating, contribute, parts, labs, fastapi, unexpected, relying, javascript, nodes, optimization, needing, suggested, dezoomcamp, proposed, delivered, simplify, largescale, reasoning, browsers, algorithms, portable, adopt, shopify, scenarios, alerting, dialects, evolution, prebuilt, launch, concurrency, nocode, release, enables, andor, treat, visibility, agentic, strategies, migrating, improved, led, scales, credentials, migrations, communicate, configuring, modelling, cursor, sports, consistency, emr, oss, volumes, driver, deployments, manages, gui, xgboost, backends, administration, attribution, isolation, sqlflow, simplicity, microservice, reliability, considerations, stat, sites, allocation, additionally, invest, driven, plans, friction, collaboration, dlt, proxy, ibis, cpu, readonly, aim, simplified, implementations, efficiency, dataengineering, device, controls, inhouse, parsing, magic, daton, integrated, orchestrator, allowing, classes, benchmarks, lockin, ipc, aimed",11.4,7.9,154.5,-0.634,946.8,55.8,8.8,231.8,10.1,18.5,17.4,203,426,126,"[https://github.com/turbolytics/sql-flow](https://github.com/turbolytics/sql-flow)

**The goal of SQLFlow is to bring the simplicity of DuckDB to streaming data.**

SQLFlow is a high-performance stream processing engine that simplifies building data pipelines by enabling you to define them using just SQL. Think of SQLFLow as a lightweight, modern Flink.

SQLFlow models stream-processing as SQL queries using the [DuckDB SQL dialect](https://duckdb.org/docs/sql/introduction.html). Express your entire stream processing pipeline—ingestion, transformation, and enrichment—as a single SQL statement and configuration file.

Process [10's of thousands of events per second](https://sql-flow.com/docs/tutorials/clickhouse-sink) on a single machine with low memory overhead, using Python, DuckDB, Arrow and Confluent Python Client.

Tap into the DuckDB ecosystem of tools and libraries to build your stream processing applications. SQLFlow supports [parquet](https://sql-flow.com/docs/tutorials/s3-parquet-sink), csv, json and [iceberg](https://sql-flow.com/docs/tutorials/iceberg-sink). Read data from Kafka.",5,5
4,"use, using, sql, etc, spark, pipeline, create, database, run, schema, api, system, processing, model, set, across, warehouse, read, storage, models, case, multiple, everything, bigquery, instead, keep, handle, doesnt, analysis, server, kafka, write, logic, iceberg, queries, large, simple, changes, users, event, parquet, datasets, json, redshift, lake, pandas, via, store, scripts, glue, memory, batch, directly, app, types, layer, databases, check, creating, metadata, key, created, processes, tests, function, custom, track, service, implement, transformations, functions, ingestion, dashboard, events, perform, separate, test, fields, transformation, cluster, requests, postgres, stream, operations, handling, efficient, errors, feature, language, replay, clickhouse, polars, stage, order, place, usage, engine, validation, runs, connect, history, maintain, must, tracking, cdc, connector, schemas, analytical, avoid, written, supports, syntax, object, allow, method, intermediate, standard, connectors, replace, lineage, relational, library, joins, transform, require, rust, execution, computation, historical, document, logs, tableau, apis, requires, notebooks, latest, inside, flow, map, reduce, include, dependencies, flink, allows, loading, form, image, looked, transactional, calls, prediction, seconds, added, querying, define, graph, template, trino, essentially, logging, defined, iot, response, dedicated, gateway, manual, arrow, checks, scenario, virtual, mongodb, silver, monitoring, becomes, inputs, billion, formats, parallel, handles, fix, lakehouse, called, efficiently, explain, schedule, templates, failure, dwh, pathway, writes, storing, loads, starts, objects, synapse, creation, overhead, factor, associated, upload, shape, properly, extraction, limitations, tags, star, methods, runtime, vector, dag, athena, consumers, log, extra, wrote, clusters, execute, interface, warehouses, provider, compare, evolve, columnar, transaction, functionality, workers, gold, cleaned, sheets, semantic, normalization, eta, queue, dataframe, hub, optimizing, generates, filtering, handled, stages, ready, detection, medallion, layers, install, achieve, causes, connected, account, hood, simpler, images, disk, individual, none, showing, ideal, everywhere, throughput, engines, cron, benchmark, components, mongo, sensor, embedded, interactive, axis, pii, difficulty, independently, rds, spin, preprocessing, calling, streams, graphql, larger, replication, node, recover, documents, enforce, scaled, flexible, logical, feasible, compression, introduce, inference, purposes, bring, provides, continuous, calculations, connects, correctly, rates, sharepoint, relationships, resulting, dimensional, monitor, released, aggregations, grid, commits, maintenance, inconsistent, builtin, fail, config, published, staging, passing, sensitive, included, sending, hubs, trigger, duplication, pytest, stores, session, avro, salesforce, indexing, costeffective, sqlite, turn, organized, materialized, pubsub, dynamodb, millions, ram, responses, redis, sessions, kinesis, third, orchestrate, comparing, pulled, snowpipe, mode, increasing, besides, extracted, prem, combination, absolutely, hdfs, tricky, component, laptop, triggers, collections, mechanism, meant, uploads, queues, understood, hosting, macros, jinja, modules, aspect, editor, rewrite, boilerplate, versioning, indexes, wall, firehose, foreach, builds, continuously, weather, straight, immutable, centralized, eventdriven, similarly, saved, selection, transforming, preferred, middle, statistical, assets, trace, variant, selfhosted, phase, powered, visualize, scheduled, scans, configs, dataflow, subscription, reduction, dynamic, pages, resolve, locations, lives, wrap, calculation, dbtcore, consists, roughly, words, asset",10.4,7.8,157.3,-0.648,963.8,56.1,8.9,235.8,10.2,19.0,17.9,200,417,119,"[https://github.com/turbolytics/sql-flow](https://github.com/turbolytics/sql-flow)

**The goal of SQLFlow is to bring the simplicity of DuckDB to streaming data.**

SQLFlow is a high-performance stream processing engine that simplifies building data pipelines by enabling you to define them using just SQL. Think of SQLFLow as a lightweight, modern Flink.

SQLFlow models stream-processing as SQL queries using the [DuckDB SQL dialect](https://duckdb.org/docs/sql/introduction.html). Express your entire stream processing pipeline—ingestion, transformation, and enrichment—as a single SQL statement and configuration file.

Process [10's of thousands of events per second](https://sql-flow.com/docs/tutorials/clickhouse-sink) on a single machine with low memory overhead, using Python, DuckDB, Arrow and Confluent Python Client.

Tap into the DuckDB ecosystem of tools and libraries to build your stream processing applications. SQLFlow supports [parquet](https://sql-flow.com/docs/tutorials/s3-parquet-sink), csv, json and [iceberg](https://sql-flow.com/docs/tutorials/iceberg-sink). Read data from Kafka.",6,6
